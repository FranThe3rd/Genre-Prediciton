{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the dataset\n",
    "def load_dataset(dataset_name=None):\n",
    "    return pd.read_csv(f'data/{dataset_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset('features_3_sec.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2, random_state=42, stratify=data['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Getting The Train Set And Test Set\n",
    "\n",
    "- This code separates the data into features (inputs) and labels (targets) for both training and testing. It also removes the `'filename'` column because it's not relevant for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=['label'])\n",
    "y = train['label']\n",
    "\n",
    "X_test = test.drop(columns=['label'])\n",
    "y_test = test['label']\n",
    "\n",
    "X = X.drop(columns=['filename'])\n",
    "\n",
    "X_test = X_test.drop(columns=['filename'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Grid Search*\n",
    "\n",
    "Takes 26 minutes to run on Cole's desktop <br>\n",
    "Best found params just in case: `{'learning_rate': 0.3, 'max_depth': 4, 'n_estimators': 100}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': [10, 25, 50, 100],\n",
    "    'learning_rate': [0.1, 0.3, 0.5],\n",
    "    'max_depth': [1, 2, 3, 4]\n",
    "}\n",
    "\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "gs = GridSearchCV(gbc, param_grid=params, cv=5, n_jobs=-1, scoring='recall_macro')\n",
    "\n",
    "gs.fit(X, y)\n",
    "\n",
    "gs.predict(X_test)\n",
    "\n",
    "print(gs.best_params_)\n",
    "print(gs.best_score_)\n",
    "\n",
    "report = classification_report(y_test, gs.predict(X_test))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Correlation Matrix Of The Model vs Actual Values*\n",
    "\n",
    "- So we can see in the diagonal values, which show correct predictions, and any significant misclassifications off the diagonal. Focus on where the model confuses similar genres to understand its weaknesses and areas for improvement.\n",
    "\n",
    "\n",
    "#### **Pop vs Disco**\n",
    "- The model predicted disco 12 times when the actual genre was pop. Conversely, it predicted pop 6 times when the actual genre was disco. This suggests the model has difficulty distinguishing between pop and disco, likely due to shared audio features like rhythm or tempo.\n",
    "\n",
    "#### **Rock vs Country**\n",
    "- The model predicted country 13 times when the actual genre was rock. Conversely, it predicted rock 9 times when the actual genre was country. This indicates the model frequently confuses rock with country, potentially due to similarities in guitar sounds, rhythms, or tempos common to both genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphing the decision, what the model predicted vs that actual value\n",
    "cm = confusion_matrix(y_test, gs.predict(X_test))\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(cm, annot=True, cmap='magma', xticklabels=['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock'], yticklabels=['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Music Genre Classification Performance Analysis*\n",
    "\n",
    "- This stacked bar chart shows the performance metrics (True Positives, True Negatives, False Positives, and False Negatives) for each music genre in a classification model. The dominance of green bars (True Negatives) and purple segments (True Positives) indicates strong overall classification performance across all genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negatives = []\n",
    "false_positives = []\n",
    "true_negatives = []\n",
    "true_positives = []\n",
    "\n",
    "for i in range(10):\n",
    "    false_negatives.append(cm[i].sum() - cm[i][i])\n",
    "    false_positives.append(cm[:, i].sum() - cm[i][i])\n",
    "    true_negatives.append(sum(np.delete(np.delete(cm, i, axis=0), i, axis=1).flatten()))\n",
    "    true_positives.append(cm[i][i])\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(np.arange(10), false_negatives, color='red', label='False Negatives')\n",
    "plt.barh(np.arange(10), false_positives, left=false_negatives, color='blue', label='False Positives')\n",
    "plt.barh(np.arange(10), true_negatives, left=np.add(false_negatives, false_positives), color='green', label='True Negatives')\n",
    "plt.barh(np.arange(10), true_positives, left=np.add(np.add(false_negatives, false_positives), true_negatives), color='purple', label='True Positives')\n",
    "plt.yticks(np.arange(10), ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock'])\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Genre')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Using Librosa To Visualize The `.wav` Files*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "audio_path = \"./audio/metal/metal.00094.wav\"\n",
    "# Load the audio file using librosa, y is the audio time series and sr is the sampling rate of y\n",
    "y, sr = librosa.load(audio_path)\n",
    "\n",
    "y_shape = np.shape(y)\n",
    "\n",
    "print(f\"y shape: {y_shape}, sample rate: {sr}, length: {y_shape[0] / sr} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "librosa.display.waveshow(y, sr=sr, color=\"#A300F9\")\n",
    "plt.title(\"Waveplot of audio file\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft = 2048\n",
    "hop_length = 512\n",
    "\n",
    "audio_file, _ = librosa.effects.trim(y)\n",
    "D = np.abs(librosa.stft(audio_file, n_fft = n_fft, hop_length = hop_length))\n",
    "\n",
    "DB = librosa.amplitude_to_db(D, ref = np.max)\n",
    "\n",
    "plt.figure(figsize = (16, 6))\n",
    "librosa.display.specshow(DB, sr = sr, hop_length = hop_length, x_axis = 'time', y_axis = 'log')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potential ways to extract features:\n",
    "`tempo, _ = librosa.beat.beat_track(y=y, sr=sr)` for tempo of a track. <br>\n",
    "`pitches, magnitudes = librosa.piptrack(y=y, sr=sr)` tracking the fundamental frequency over time. <br>\n",
    "`harmonic, percussive = librosa.effects.hpss(y)` to separate the audio into harmonic and percussive parts. <br>\n",
    "`spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)` measures the difference between the peaks and valleys in a audio. <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
